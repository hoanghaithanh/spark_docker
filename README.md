# Spark + Jupyter in Docker

This repository provides a **Dockerized environment for Apache Spark with Jupyter Notebook integration**, making it easy to develop, test, and run Spark applications locally or in a containerized setup.

## ðŸš€ Features

- **Jupyter Notebook** with root access and persistent workspace
- **Apache Spark 4.0.0**
  - Spark Master with web UI exposed
  - Spark Worker nodes connected automatically
- Shared **data volume** for exchanging files between Jupyter and Spark
- Pre-configured networking with an external Hadoop cluster (via `docker-hadoop_default` network)
- Ready-to-use environment with minimal setup

## ðŸ“¦ Services

| Service        | Description                                   | Ports              |
|----------------|-----------------------------------------------|-------------------|
| `jupyter`      | Jupyter Notebook with Spark access            | configured by token |
| `spark-master` | Spark Master node with web UI                 | `9090` (UI), `7077` |
| `spark-worker` | Spark Worker node connected to Spark Master   | N/A               |

## ðŸ›  Prerequisites

- [Docker](https://www.docker.com/get-started)  
- [Docker Compose](https://docs.docker.com/compose/)  
- An existing external Docker network named `docker-hadoop_default` (for Hadoop integration)  

To create the network (if not already available):

```bash
docker network create docker-hadoop_default
```

## ðŸ“‚ Folder Structure
```bash
spark_docker/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ jupyter/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ volume/       # Mounted workspace for notebooks
â”œâ”€â”€ data/             # Shared data between Jupyter and Spark
â””â”€â”€ ...
```

## âš¡ Usage

### 1. Clone the Repository

```bash
git clone https://github.com/hoanghaithanh/spark_docker.git
cd spark_docker
```

### 2. Set Jupyter Token  
Update your `.env` file or export a token before starting:

```bash
export JUPYTER_TOKEN=your_secure_token
```

### 3. Start the Services

```bash
docker-compose up -d
```

### 4. Access the Services
- Jupyter Notebook: http://localhost:8888  
- Spark Master Web UI: http://localhost:9090

## ðŸ“Š Volumes

- `./jupyter/volume` â†’ `/home/jovyan/work` (Jupyter workspace)  
- `./data` â†’ `/home/jovyan/data` (Shared data)  
- `/etc/letsencrypt` â†’ `/etc/letsencrypt` (SSL certificates if available)  

## ðŸ”§ Stopping the Services
```bash
docker-compose down
```


## ðŸ“œ License

This project is licensed under the MIT License â€“ feel free to use and modify.

---

ðŸ’¡ Tip: You can extend this setup with additional Spark workers by scaling the `spark-worker` service:
```bash
docker-compose up -d --scale spark-worker=3
```
